{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMTrO1gkNQMeZsqYSt1Gbh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msdayi/NesneProje/blob/main/20210305011_MustafaDay%C4%B1o%C4%9Flu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMiO_WwkInAz",
        "outputId": "51918b31-0f39-4ee9-c3c8-300966248a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark py4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "My5_wr1aHdeu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
      ],
      "metadata": {
        "id": "zJZVnTkfHj-5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.text(\"book.txt\")"
      ],
      "metadata": {
        "id": "pjxNdUWNHkG7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deDxIu8XHkJg",
        "outputId": "e1e46e8f-ef81-49b8-e995-dd3336e4f5fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|The Project Guten...|\n",
            "|                    |\n",
            "|                    |\n",
            "|This ebook is for...|\n",
            "|                    |\n",
            "|Title: The Advent...|\n",
            "|                    |\n",
            "|Author: Arthur Co...|\n",
            "|                    |\n",
            "|                    |\n",
            "|                    |\n",
            "|Release date: Mar...|\n",
            "|                    |\n",
            "|Most recently upd...|\n",
            "|                    |\n",
            "|   Language: English|\n",
            "|                    |\n",
            "|Credits: an anony...|\n",
            "|                    |\n",
            "|                    |\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.textFile(\"book.txt\")"
      ],
      "metadata": {
        "id": "AV6w_jERHkLq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = (rdd.flatMap(lambda line: line.split()).map(lambda word: (word.lower(),1)).reduceByKey(lambda a, b: a + b))"
      ],
      "metadata": {
        "id": "JDhOHdJMHkRP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_word_counts = word_counts.sortBy(lambda x: x[1], ascending = False)"
      ],
      "metadata": {
        "id": "RDSlvi7vIrGi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in sorted_word_counts.take(100): print(f\"{count} word '{word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHUwpdBqIrN7",
        "outputId": "495fb5f2-543c-4c5e-d0ff-dd253cf6aac8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5716 word 'the'\n",
            "2878 word 'and'\n",
            "2760 word 'of'\n",
            "2721 word 'to'\n",
            "2648 word 'a'\n",
            "2533 word 'i'\n",
            "1761 word 'in'\n",
            "1604 word 'that'\n",
            "1371 word 'was'\n",
            "1278 word 'he'\n",
            "1267 word 'it'\n",
            "1176 word 'you'\n",
            "1146 word 'his'\n",
            "1080 word 'is'\n",
            "955 word 'my'\n",
            "903 word 'have'\n",
            "869 word 'with'\n",
            "848 word 'as'\n",
            "813 word 'had'\n",
            "769 word 'at'\n",
            "755 word 'which'\n",
            "727 word 'for'\n",
            "613 word 'be'\n",
            "610 word 'not'\n",
            "540 word 'but'\n",
            "502 word 'we'\n",
            "498 word 'from'\n",
            "465 word 'this'\n",
            "461 word 'upon'\n",
            "447 word 'said'\n",
            "414 word 'me'\n",
            "397 word 'there'\n",
            "389 word 'she'\n",
            "385 word 'been'\n",
            "379 word 'your'\n",
            "377 word 'her'\n",
            "377 word 'very'\n",
            "366 word 'on'\n",
            "354 word 'by'\n",
            "349 word '“i'\n",
            "338 word 'all'\n",
            "337 word 'were'\n",
            "336 word 'an'\n",
            "336 word 'so'\n",
            "323 word 'are'\n",
            "317 word 'would'\n",
            "312 word 'what'\n",
            "308 word 'one'\n",
            "299 word 'no'\n",
            "295 word 'when'\n",
            "284 word 'could'\n",
            "280 word 'has'\n",
            "275 word 'out'\n",
            "272 word 'into'\n",
            "266 word 'or'\n",
            "262 word 'mr.'\n",
            "261 word 'who'\n",
            "257 word 'little'\n",
            "255 word 'if'\n",
            "254 word 'will'\n",
            "253 word 'him'\n",
            "250 word 'up'\n",
            "238 word 'some'\n",
            "235 word 'do'\n",
            "210 word 'our'\n",
            "208 word 'should'\n",
            "205 word 'may'\n",
            "205 word 'down'\n",
            "201 word 'holmes'\n",
            "194 word 'man'\n",
            "190 word 'see'\n",
            "181 word 'am'\n",
            "176 word 'they'\n",
            "171 word 'shall'\n",
            "170 word 'about'\n",
            "169 word 'must'\n",
            "169 word 'can'\n",
            "163 word 'over'\n",
            "162 word 'any'\n",
            "160 word 'than'\n",
            "160 word 'then'\n",
            "156 word 'only'\n",
            "152 word 'more'\n",
            "144 word 'other'\n",
            "142 word 'came'\n",
            "141 word 'before'\n",
            "137 word 'know'\n",
            "137 word 'did'\n",
            "135 word 'two'\n",
            "133 word 'think'\n",
            "133 word '“it'\n",
            "126 word 'us'\n",
            "125 word 'holmes,'\n",
            "123 word 'might'\n",
            "123 word 'come'\n",
            "120 word '“you'\n",
            "119 word 'just'\n",
            "115 word 'now'\n",
            "115 word 'how'\n",
            "114 word 'such'\n"
          ]
        }
      ]
    },
    {
      "source": [
        "letters = rdd.flatMap(lambda line: list(line[0].lower()) if line else []) # If the line is empty, it returns an empty list preventing the IndexError.\n",
        "#Otherwise, it proceeds with the original logic.\n",
        "\n",
        "letters = letters.filter(lambda char: char.isalpha())\n",
        "\n",
        "letter_counts = letters.map(lambda letter: (letter, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "sorted_letter_counts = letter_counts.sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "print(\"En sık geçen harfler:\")\n",
        "for letter, count in sorted_letter_counts.collect():\n",
        "    print(f\"{letter}: {count}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y07IWvY8LzQQ",
        "outputId": "4e315785-8fe4-43f0-8cdf-96be17d1f2de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En sık geçen harfler:\n",
            "i: 82\n",
            "t: 82\n",
            "h: 50\n",
            "s: 37\n",
            "a: 34\n",
            "w: 23\n",
            "l: 14\n",
            "m: 12\n",
            "o: 11\n",
            "v: 9\n",
            "b: 7\n",
            "p: 6\n",
            "x: 6\n",
            "f: 6\n",
            "r: 4\n",
            "c: 3\n",
            "j: 2\n",
            "d: 1\n",
            "n: 1\n",
            "u: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = rdd.flatMap(lambda line: zip(line.split()[:-1], line.split()[1:]) if len(line.split()) > 1 else []) # Check if the line has more than one word after splitting.\n",
        "# If not, return an empty list to avoid the IndexError. Otherwise, proceed with the original logic.\n",
        "\n",
        "bigram_counts = bigrams.map(lambda pair: (f\"{pair[0]} {pair[1]}\", 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "sorted_bigram_counts = bigram_counts.sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "print(\"En sık geçen bigram'ler:\")\n",
        "for bigram, count in sorted_bigram_counts.take(10):\n",
        "    print(f\"{bigram}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEPU9_X1Mi0g",
        "outputId": "f3c33fdf-93f8-446b-b456-7b9737ba64a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En sık geçen bigram'ler:\n",
            "of the: 736\n",
            "in the: 497\n",
            "to the: 312\n",
            "I have: 247\n",
            "that I: 245\n",
            "at the: 227\n",
            "upon the: 195\n",
            "to be: 191\n",
            "and I: 191\n",
            "and the: 189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "characters = rdd.flatMap(lambda line: list(line) if line else [])  # If the line is empty, return an empty list. Otherwise, proceed to convert the line to a list of characters.\n",
        "\n",
        "character_counts = characters.map(lambda char: (char, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "sorted_character_counts = character_counts.sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "print(\"En sık geçen karakterler:\")\n",
        "for char, count in sorted_character_counts.take(10):\n",
        "    print(f\"{char}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB9g5AIkNTCG",
        "outputId": "3fbe5db8-5742-4ae4-cf51-486245d5dccd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En sık geçen karakterler:\n",
            " : 104942\n",
            "e: 54608\n",
            "t: 39247\n",
            "a: 35298\n",
            "o: 34476\n",
            "n: 29328\n",
            "h: 28311\n",
            "i: 27356\n",
            "s: 27079\n",
            "r: 25423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df.rdd.flatMap(lambda line: line[0].split('.'))\n",
        "\n",
        "sentence_lengths = sentences.map(lambda sentence: len(sentence.split()))\n",
        "\n",
        "total_sentences = sentence_lengths.count()\n",
        "total_words = sentence_lengths.reduce(lambda a, b: a + b)\n",
        "average_sentence_length = total_words / total_sentences\n",
        "\n",
        "print(f\"Ortalama cümle uzunluğu: {average_sentence_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ8we9olONmd",
        "outputId": "58271a25-52ff-4aa5-dc49-149598611753"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ortalama cümle uzunluğu: 9.226961157654227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split, explode, lower, length, col, count, size\n",
        "\n",
        "# Assuming 'df' contains the raw text data in a column named 'value'\n",
        "# Split the lines into words and explode to create a new row for each word\n",
        "words_df = df.select(explode(split(col(\"value\"), \" \")).alias(\"word\"))\n",
        "\n",
        "# Calculate the total number of words in the DataFrame\n",
        "total_words = words_df.count()\n",
        "\n",
        "print(f\"Total words: {total_words}\")\n",
        "\n",
        "# Further processing for 'pct_she' would require more context about the data and how it should be calculated.\n",
        "# For example, you could filter for words that match 'she' and divide by total_words to get a percentage."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBZdJ3iqO-A4",
        "outputId": "c58e104b-64e2-41c4-f72b-eaaa03248610"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 110329\n"
          ]
        }
      ]
    }
  ]
}